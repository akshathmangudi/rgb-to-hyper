# rgb-to-hyper
end-to-end implementation of microplastics detection in water using hyperspectral imaging.

# How it works

Summary of the Training and Prediction Flow

A. Training Flow (mode = "global"):

1. Model and Optimizer Initialization:
   - Instantiate Generator and Discriminator.
   - Initialize their respective Adam optimizers.

2. Logging Setup:
   - Create a summary_writer for TensorBoard to log training metrics.

3. Checkpoint Path Determination:
     - Set checkpoint_path to 'global_ckpt' for global training.

4. Training Execution:
   - Call train_gan with all necessary parameters.
   - Inside train_gan:
     - Checkpoint Restoration: Load existing checkpoints if available.
     - Data Loading and Preparation: Load and preprocess paired RGB and HSI images.
     - Epoch Loop: For each epoch, shuffle data and iterate over batches.
       - Batch Processing: Perform augmentation, train discriminator, train generator, compute metrics, and log progress.
       - Checkpoint Saving: Save model states at the end of each epoch.
     - Post-Training: Save final metrics and optionally generate sample outputs.


B. Prediction Flow (mode = "predict")

1. Checkpoint Restoration:
  - Use load_model_and_predict to load the Generator model from the 'global_ckpt' directory.

2. Data Loading:
   - Load RGB images designated for prediction.

3. HSI Generation:
  - Use the restored Generator to create HSI images from the RGB inputs.

4. Output Saving:
   - Save the generated HSI images as TIFF files in the specified directory.

# Underlying Mathematics of the Model

The project utilizes a **Generative Adversarial Network (GAN)** framework, specifically tailored to convert RGB images to HyperSpectral Imaging (HSI) data. Below is a breakdown of the mathematical concepts and components that underpin the model.

### 1. Generative Adversarial Networks (GANs)

**GANs** consist of two neural networks, the **Generator** and the **Discriminator**, which are trained simultaneously through adversarial processes.

- **Generator (\(G\))**:
  - **Purpose**: Generates synthetic HSI images from input RGB images.
  - **Mathematical Objective**: ![equation](https://latex.codecogs.com/png.latex?G:%20%5Cmathbb%7BR%7D%5E%7BH%20%5Ctimes%20W%20%5Ctimes%203%7D%20%5Crightarrow%20%5Cmathbb%7BR%7D%5E%7BH%20%5Ctimes%20W%20%5Ctimes%20C%7D) are image dimensions, and C is the number of HSI channels.

- **Discriminator (\(D\))**:
  - **Purpose**: Differentiates between real HSI images and those generated by \(G\).
  - **Mathematical Objective**:![equation](https://latex.codecogs.com/png.latex?D%3A%20%5Cmathbb%7BR%7D%5E%7BH%20%5Ctimes%20W%20%5Ctimes%20C%7D%20%5Crightarrow%20%5B0%2C1%5D), outputting the probability that an input image is real.

**Adversarial Loss**:
The Generator and Discriminator engage in a minimax game with the following objective functions:

- **Discriminator Loss (\( \mathcal{L}_D \))**:
 ![Discriminator Loss](https://latex.codecogs.com/png.latex?%5Cmathcal%7BL%7D_D%20%3D%20-%5Cmathbb%7BE%7D_%7Bx%20%5Csim%20p_%7B%5Ctext%7Bdata%7D%7D%7D%5B%5Clog%20D%28x%29%5D%20-%20%5Cmathbb%7BE%7D_%7Bz%20%5Csim%20p_z%7D%5B%5Clog%281%20-%20D%28G%28z%29%29%29%5D)

- **Generator Loss (\( \mathcal{L}_G \))**:
 ![Generator Loss](https://latex.codecogs.com/png.latex?%5Cmathcal%7BL%7D_G%20%3D%20-%5Cmathbb%7BE%7D_%7Bz%20%5Csim%20p_z%7D%5B%5Clog%20D%28G%28z%29%29%5D)


**Wasserstein GAN with Gradient Penalty (WGAN-GP)**:
To improve training stability, the model incorporates WGAN-GP, which modifies the loss functions to enforce the Lipschitz constraint using a gradient penalty.

- **Gradient Penalty (\( \mathcal{L}_{GP} \))**:
  ![Gradient Penalty](https://latex.codecogs.com/png.latex?%5Cmathcal%7BL%7D_%7BGP%7D%20%3D%20%5Clambda%20%5Cmathbb%7BE%7D_%7B%5Chat%7Bx%7D%20%5Csim%20P_%7B%5Chat%7Bx%7D%7D%7D%20%5Cleft%5B%20%28%5C%7C%5Cnabla_%7B%5Chat%7Bx%7D%7D%20D%28%5Chat%7Bx%7D%29%5C%7C_2%20-%201%29%5E2%20%5Cright%5D)
  where \( \hat{x} \) are samples interpolated between real and generated data, and \( \lambda \) is the penalty coefficient.

- **Modified Discriminator Loss**:
 ![Modified Discriminator Loss](https://latex.codecogs.com/png.latex?%5Cmathcal%7BL%7D_D%20%3D%20%5Cmathbb%7BE%7D_%7Bx%20%5Csim%20p_%7B%5Ctext%7Bdata%7D%7D%7D%5BD%28x%29%5D%20-%20%5Cmathbb%7BE%7D_%7Bz%20%5Csim%20p_z%7D%5BD%28G%28z%29%29%5D%20%2B%20%5Cmathcal%7BL%7D_%7BGP%7D)

### 2. Spectral Normalization

**Spectral Normalization** is applied to the Discriminator to stabilize training by constraining the Lipschitz constant of each layer.

- **Mathematical Basis**:
  ![Spectral Normalization](https://latex.codecogs.com/png.latex?%5Chat%7BW%7D%20%3D%20%5Cfrac%7BW%7D%7B%5Csigma%28W%29%7D)

  where \( \sigma(W) \) is the largest singular value of weight matrix \( W \).

- **Implementation**:
  Iteratively approximates the dominant singular vectors using power iterations to compute \( \sigma(W) \).

### 3. Loss Functions

Beyond adversarial losses, the model incorporates several auxiliary loss functions to enhance the quality and fidelity of generated HSI images.

- **Mean Squared Error (MSE)**:
  ![MSE](https://latex.codecogs.com/png.latex?%5Ctext%7BMSE%7D%20%3D%20%5Cfrac%7B1%7D%7BN%7D%20%5Csum_%7Bi%3D1%7D%5EN%20%28y_i%20-%20%5Chat%7By%7D_i%29%5E2)
  
  Measures the average squared difference between the generated and real HSI pixels.

- **Peak Signal-to-Noise Ratio (PSNR)**:
  ![PSNR](https://latex.codecogs.com/png.latex?%5Ctext%7BPSNR%7D%20%3D%2020%20%5Ccdot%20%5Clog_%7B10%7D%5Cleft%28%5Cfrac%7B%5Ctext%7BMAX%7D_I%7D%7B%5Csqrt%7B%5Ctext%7BMSE%7D%7D%7D%5Cright%29)

  where \( \text{MAX}_I \) is the maximum possible pixel value. PSNR assesses the quality of reconstruction.

- **Spectral Angle Mapper (SAM)**:
  ![SAM](https://latex.codecogs.com/png.latex?%5Ctext%7BSAM%7D%28y%2C%20%5Chat%7By%7D%29%20%3D%20%5Carccos%5Cleft%28%20%5Cfrac%7By%20%5Ccdot%20%5Chat%7By%7D%7D%7B%5C%7Cy%5C%7C%20%5C%5C%20%5C%7C%5Chat%7By%7D%5C%7C%7D%20%5Cright%29)
  Measures the spectral similarity between two spectra \( y \) and \( \hat{y} \), providing angular differences in high-dimensional space.

- **Perceptual Loss**:
  Utilizes a pre-trained VGG19 network to compute the loss in a feature space, capturing high-level perceptual differences.
 ![Perceptual Loss](https://quicklatex.com/cache3/9d/ql_c06dfe1c6d14858f5af82f32ffce319d_l3.png)
  where \( \phi_i \) represents the activation maps from layer \( i \) of VGG19.

### 4. Training Objectives

The overall objective combines adversarial and auxiliary losses to train the Generator and Discriminator.

- **Generator Objective**:
  ![Generator Objective](https://latex.codecogs.com/png.latex?%5Cmathcal%7BL%7D_G%5E%7B%5Ctext%7Btotal%7D%7D%20%3D%20%5Cmathcal%7BL%7D_G%20%2B%20%5Clambda_%7B%5Ctext%7Bpixel%7D%7D%20%5Ccdot%20%5Cmathcal%7BL%7D_%7B%5Ctext%7BMSE%7D%7D%20%2B%20%5Clambda_%7B%5Ctext%7Bperceptual%7D%7D%20%5Ccdot%20%5Cmathcal%7BL%7D_%7B%5Ctext%7Bperceptual%7D%7D)
  Balances adversarial objectives with pixel-wise and perceptual fidelity.

- **Discriminator Objective**:
  ![Discriminator Objective](https://latex.codecogs.com/png.latex?%5Cmathcal%7BL%7D_D%5E%7B%5Ctext%7Btotal%7D%7D%20%3D%20%5Cmathcal%7BL%7D_D)
  Primarily focuses on differentiating real from generated data with the gradient penalty for stability.

### 5. Optimization

Both networks are optimized using gradient-based methods, typically Adam optimizer, updating weights to minimize their respective loss functions.

- **Parameter Updates**:
  ![Discriminator Update](https://latex.codecogs.com/png.latex?%5Ctheta_D%20%5Cleftarrow%20%5Ctheta_D%20-%20%5Ceta%20%5Ccdot%20%5Cnabla_%7B%5Ctheta_D%7D%20%5Cmathcal%7BL%7D_D%5E%7B%5Ctext%7Btotal%7D%7D)

![Generator Update](https://latex.codecogs.com/png.latex?%5Ctheta_G%20%5Cleftarrow%20%5Ctheta_G%20-%20%5Ceta%20%5Ccdot%20%5Cnabla_%7B%5Ctheta_G%7D%20%5Cmathcal%7BL%7D_G%5E%7B%5Ctext%7Btotal%7D%7D)

  where \( \eta \) is the learning rate.

### 6. Evaluation Metrics

Post-training, the model's performance is evaluated using the aforementioned metrics (MSE, PSNR, SAM) to quantify the quality of generated HSI images.

- **Average Metrics Calculation**:
![Average Metrics Calculation](https://quicklatex.com/cache3/1a/ql_cfc328f59a4e8cc35f057ddf169f431a_l3.png) Aggregates performance across all batches and epochs.

### 7. Additional Considerations

- **Data Augmentation**:
  Enhances model generalization by applying transformations like rotations, flips, and scaling to the training data.

- **Checkpointing**:
  Saves model states periodically to allow resumption and prevent loss of progress due to interruptions.

- **Logging**:
  Records training progress and metrics for monitoring and debugging purposes.

### Summary

The model integrates advanced GAN architectures with specialized loss functions and normalization techniques to effectively translate RGB images into high-fidelity HSI data. The mathematical framework ensures stability during training, preserves spectral integrity, and evaluates model performance comprehensively.
